\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Exercise 1}{1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:gaus}{{\caption@xref {fig:gaus}{ on input line 160}}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces (a) Convex function with known minimum value and it's analytical derivative. The dots are the calculated minima according to gradient descent. (b) Contour plot of the gradient of a scalar function with vector-valued arguments. The dots are the calculated minima according to gradient descent.\relax }}{1}}
\newlabel{fig:gaus}{{\caption@xref {fig:gaus}{ on input line 167}}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The solid line is the function, the dashed line is it's analytical derivative, and the series of dots is the series of minimum guesses from gradient descent. (a) Initial guess: 5, step: 0.5, threshold: 0.1 converges in 9 iterations. (b) Initial guess: 5, step: 0.2, threshold: 0.1 converges in 20 iterations. (c) Initial guess: 4, step: 2, threshold: 0.1 converges in 59992 iterations. (d) Initial guess: 0, step: 0.5, threshold: 0.1 converges in 1 iteration, but does not converge to the correct minimum. \relax }}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Exercise 2}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Exercise 3}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Exercise 4}{2}}
